<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization">
  <meta name="keywords" content="Diffusion Model, Quantization, Efficent Deep Learning ">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- 
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">MixDQ: Memory-Efficient Few-Step  Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/TianchenZhao">Tianchen Zhao</a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/XuefeiNing">Xuefei Ning</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/TongchengFang">Tongcheng fang</a><sup>1,2*</sup>,
            </span>
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/EnshuLiu">Enshu Liu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://hgyhungry.github.io/">Guyue Huang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/zinanlin/">Zinan Lin</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=SvE3bdUAAAAJ&hl=en">Shengen Yan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://dai.sjtu.edu.cn/pepledetail.html?id=218">Guohao Dai</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/YuWang">Yu Wang</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>Infinigence AI</span>
            <span class="author-block"><sup>3</sup>University of California Santa Barbara</span>
            <span class="author-block"><sup>4</sup>Microsoft</span>
            <span class="author-block"><sup>5</sup>Shanghai Jiao Tong University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://nicsefc.ee.tsinghua.edu.cn/%2Fnics_file%2Fpdf%2F483f5379-b857-4cb2-b114-caaa366deaad.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2307.08209"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Sides Link. -->
              <span class="link-block">
                <a href="https://nicsefc.ee.tsinghua.edu.cn/%2Fnics_file%2Fpdf%2Fa3462020-25d8-436c-993f-7aaf047cbd93.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-alt"></i>
                  </span>
                  <span>Slides</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/A-suozhang/Ada3D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- [The Teaser Video Exmaple] -->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop height="100%">
        <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">

  <div class="container is-max-desktop">

    <!--/ Poster. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Poster</h2>
        <div class="publication-poster">
          <img src="./static/src/poster.png"
            class="poster"
            lt="Poster."/> -->
            <!-- <embed src="./static/src/poster.pdf" width="1600px" height="900px" /> -->
        <!-- </div>
      </div>
    </div> 
    <!--/ Video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Video</h2>
        <div class="publication-poster">
          <iframe width="1080" height="720" src="https://www.youtube.com/embed/N_llpMqMJbk?si=C38fAW1gYxCQFtLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->
            <!-- <embed src="./static/src/poster.pdf" width="1600px" height="900px" /> -->
        <!-- </div>
      </div>
    </div> 
      <!--/ Teaser. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Teaser</h2>
          <div class="publication-teaser">
            <img src="./static/src/teaser.png"
              class="teaser"
              lt="Teaser."
              style="width: 90%"
              />
              <!-- <embed src="./static/src/teaser.png" width="1600px" height="900px" /> -->
          </div>
        </div>
      </div>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion models have achieved significant visual generation quality. However, their <b>significant computational and memory costs</b> pose challenge for their application on resource-constrained mobile devices or even desktop GPUs. Recent <b>few-step diffusion models</b> reduces the inference time by reducing the denoising steps. However, their memory consumptions are still excessive. 
          </p>
          <p>
            The <b>Post Training Quantization (PTQ)</b> replaces high bit-width FP representation with low-bit integer values (INT4/8) , which is an effective and efficient technique to reduce the memory cost. However, when applying to few-step diffusion models, existing quantization methods <b>face challenges in preserving both the image quality and text alignment</b>. 
          </p>
          <p>
            To address this issue, we propose an <b>mixed-precision quantization framework - MixDQ</b>. Firstly, We design specialized BOS-aware quantization method for highly sensitive text embedding quantization. Then, we conduct metric-decoupled sensitivity analysis to measure the sensitivity of each layer. Finally, we develop an integer-programming-based method to conduct bit-width allocation. 
          </p>
          <p>
            While existing quantization methods fall short at W8A8, MixDQ could achieve <b>W8A8 without performance loss</b>, and <b>W4A8 with negligible visual degradation</b>. Compared with FP16, we achieve <b>3-4x</b> reduction in model size and memory cost, and <b>1.45x</b> latency speedup. 
          </p>
        </div>
      </div>
    </div>


    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="src.mp4"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->

  </div>
</section>


<section class="section">
  <!-- Motivation. -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Motivation</h2>

        <!-- Generalization. -->
        <h3 class="title is-4">Challenges for Quantizing Few-step Diffusion Models</h3>
        <div class="content has-text-justified">
          <p>
            We empirically discover that the few-step diffusion models are more sensitive to quantization compared with multi-step diffusion models, and prior diffusion quantization methods faces challenges. Q-diffusion W8A8 quantized model faces severe <b>quality degradation</b> under few-steps. Also, even with multi-step model, quantization harms the <b>text-image alignment</b>. 
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/src/quant_problem.png"
          class="exp-image"
          alt="Experimental Results Image."
          style="width: 75%"/>
        </div>
        <h3 class="title is-4">Preliminary Experiments: Reasons for Quantization Failure</h3>
        <div class="content has-text-justified">
          <p>
            We conduct preliminary experiments to delve into the reasons for quantization failure, and discover two insightful findings: (1) The quantization are "bottlenecked" by some highly sensitive layers. (2) Quantizing different part of the model affects generated image quality and content repsectively. 
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/src/quant_fail_error.png"
          class="exp-image"
          alt="Experimental Results Image."
          style="width: 90%"/>
        </div>

        <br/>
        <!--/ Generalization. -->
      </div>
    </div>
  <!--/ Motivation. -->
  </div>
</div>
<section class="section">
  <!-- Motivation. -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Methodology</h2>
        To overcome the above challenges, inspired by the above findings, we design <b>MixDQ</b>, a mixed-precision quantization framework:

        <div class="content has-text-centered">
          <img src="./static/src/mixdq_method.png"
          class="exp-image"
          alt="Experimental Results Image."
          style="width: 100%"/>
        </div>

        <!-- Generalization. -->
        <h3 class="title is-4">BOS-aware Text Embedding Quantization</h3>
        <div class="content has-text-justified">
          <p>
            We discover that the 1st token of the CLIP text embedding is the outlier that hinders quantization. Further, we notice that the first token is the <b>Begin-Of-Sentence (BOS) token</b> that remains the same for different prompts. Therefore, we could pre-compute it  offline and skip its quantization. 
          </p>
        </div>
        <!-- <div class="content has-text-centered">
          <img src="./static/src/bos_aware.png"
          class="exp-image"
          alt="Experimental Results Image."
          style="width: 100%"/>
        </div>
        <br/> -->
        <!--/ Generalization. -->

        <!-- Generalization. -->
        <h3 class="title is-4">Metric-Decoupled Sensitivity Analysis</h3>
        <div class="content has-text-justified">
          <p>
            When simply remaining the layers that causes the most quantization error FP16, we discover that the generated image still faces quality degradation, denoting <b>existing quantization sensitivity analysis's accuracy needs improving</b>. Inspired by the quantization's affects on image quality and textual alignmet, we design a Metric-Decoupled Sensitivity Analysis method. We seperate the layers into 2 groups, and conduct sensitivity analysis with distinct metrics repsectively for them. 
          </p>
        </div>
        <!-- <div class="content has-text-centered">
          <img src="./static/src/density.png"
          class="exp-image"
          alt="Experimental Results Image."
          width="1600px" height="600px"/>
        </div> -->
        <br/>
        <h3 class="title is-4">Integer-Programming-based Bit-width Allocation</h3>
        <div class="content has-text-justified">
          <p>
            After acquiring the quantization sensitivity, we formulate the bit-width allocation problem into an integer-programming method, and adopt off-the-shelf solver to efficiently solve them. 
          </p>
        </div>
        <!-- <div class="content has-text-centered">
          <img src="./static/src/spbn.png"
          class="exp-image"
          alt="Experimental Results Image."
          width="800px" height="400px"/>
        </div> -->
        <br/>
        <!--/ Generalization. -->
        <br/>
                
      </div>
    </div>
  <!--/ Motivation. -->
  </div>
</div>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3"> Experiments and Analysis:  </h2>
          <!-- Perf. -->
          <h3 class="title is-4"> 🖼️  Generation Quality</h3>
          <div class="content has-text-justified">
            <p>
              We present the performance of MixDQ on COCO text-to-image task. We choose multiple metrics that reflect different aspect of the generated images. The FID for image fidelity (quality), the CLIPScore for textual alignment, and the ImageReward for human preference. MixDQ could achieve W8A8 without performance loss. With just 0.1/0.5 FID increase, MixDQ could achivee W5A8/W4A8. At the same time, the baseline quantization methods fall short at W8A8 (60 FID increase, negative ImageReward).   
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/src/mixdq_main_result.png"
            class="exp-image"
            alt="Experimental Results Image."
            style="width: 70%"/>  
          </div>
            <p>
              We present some qualitative results that relates the statistical metric values with generated image. As could be seen, compared with Q-Diffusion and naive minmax quantization. MixDQ-W4A8 could generate image nearly identical with the FP image, while other methods fail to produce readable image for W8A8. 
            </p>
          <div class="content has-text-centered">
            <img src="./static/src/mixdq_line_plot.png"
            class="exp-image"
            alt="Experimental Results Image."
            style="width: 80%"/>  
          </div>
        <!--/ Perf. -->
        <!-- AttnMap. -->
        <h3 class="title is-4"> 🧭 Efficiency Improvement</h3>
        <div class="content has-text-justified">
          <p>
            We test the efficiency improvement of MixDQ quantization with hardware profiling. As could be seen, MixDQ could achive 3-4x memory compression rate, and 1.4-1.6x latency speedup with W4A8. 
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/src/mixdq_hardware_stats.png"
          class="geo-vis"
          alt="Attention map visualization."/>
        </div>
        <h3 class="title is-4"> 🤗 Open-Source Demo</h3>
          <p>
            We implement efficient INT8 GPU kernel implementation for practical hardware acceleration on GPU. We present MixDQ model's  huggingface pipeline, which could be efficiently called with a few lines of codes. It achives 2x model size reduction, and 1.45x end-to-end latency speedup. 
          </p>
        <div class="content has-text-centered">
          <img src="./static/src/demo_mixdq_pipeline.png"
          class="geo-vis"
          alt="Attention map visualization."/>
        </div>
        <p>
          Compared with other existing diffusion model quantization tools. Only the closed-form TensorRT INT8 implementation achieves practical latency speedup. MixDQ is the 1st to achieve practical memory and latency optimization for few-step diffusion models, enabling "tiny and fast" image generation. 
        </p>
        <div class="content has-text-centered">
          <img src="./static/src/comparison_quant_deploy2.png"
          class="exp-image"
          alt="Experimental Results Image."
          style="width: 80%"/>
        </div>
        <!--/ AttnMap. -->
        <h3 class="title is-4">Ablation Studies</h3>
        <div class="content has-text-centered">
          <img src="./static/src/mixdq_ablation.png"
          class="exp-image"
          alt="Experimental Results Image."
          style="width: 80%"/>
        </div>
        <!-- Geo-vis. -->
        <h3 class="title is-4">Qualitative Results</h3>
        <div class="content has-text-centered">
          <img src="./static/src/mixdq_qualitatives.png"
          class="geo-vis"
          alt="Attention map visualization."
          style="width: 80%"/>
        </div>
      </div>
    </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Zhao2023Ada3DE,
      title={Ada3D : Exploiting the Spatial Redundancy with Adaptive Inference for Efficient 3D Object Detection},
      author={Tianchen Zhao and Xuefei Ning and Ke Hong and Zhongyuan Qiu and Pu Lu and Yali Zhao and Linfeng Zhang and Lipu Zhou and Guohao Dai and Huazhong Yang and Yu Wang},
      journal={ArXiv},
      year={2023},
      volume={abs/2307.08209},
      url={https://api.semanticscholar.org/CorpusID:259937318}
    }</code></pre>
  </div>
  <!-- <div class="content has-text-centered">
    <img src="./static/src/pr.png"
    class="geo-vis"
    alt="Attention map visualization."/>
  </div> -->
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2307.08209">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/A-suozhang/ada3d" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
